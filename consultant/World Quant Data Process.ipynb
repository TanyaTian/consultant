{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T03:46:26.688300Z",
     "start_time": "2025-04-02T03:46:26.199886Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from machine_lib_output import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8c63d3f3c14cc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T03:46:33.507541Z",
     "start_time": "2025-04-02T03:46:32.223123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"user\":{\"id\":\"YT33830\"},\"token\":{\"expiry\":14400.0},\"permissions\":[\"BEFORE_AND_AFTER_PERFORMANCE_V2\",\"CONSULTANT\",\"MULTI_SIMULATION\",\"PROD_ALPHAS\",\"REFERRAL\",\"VISUALIZATION\",\"WORKDAY\"]}'\n"
     ]
    }
   ],
   "source": [
    "s = login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bddd7ae23161c38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T04:49:43.335032Z",
     "start_time": "2025-04-01T04:49:34.651767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别 'analyst' 的数据已追加到 data/GLB/categories_delay1.csv\n",
      "类别 'insiders' 未返回数据\n",
      "类别 'insiders' 未返回数据\n",
      "类别 'fundamental' 的数据已追加到 data/GLB/categories_delay1.csv\n",
      "类别 'macro' 的数据已追加到 data/GLB/categories_delay1.csv\n",
      "类别 'model' 的数据已追加到 data/GLB/categories_delay1.csv\n",
      "类别 'news' 的数据已追加到 data/GLB/categories_delay1.csv\n",
      "类别 'option' 未返回数据\n",
      "类别 'option' 未返回数据\n",
      "类别 'other' 的数据已追加到 data/GLB/categories_delay1.csv\n",
      "类别 'pv' 的数据已追加到 data/GLB/categories_delay1.csv\n",
      "类别 'risk' 的数据已追加到 data/GLB/categories_delay1.csv\n",
      "类别 'sentiment' 未返回数据\n",
      "类别 'sentiment' 未返回数据\n",
      "类别 'socialmedia' 未返回数据\n",
      "类别 'socialmedia' 未返回数据\n",
      "类别 'earnings' 的数据已追加到 data/GLB/categories_delay1.csv\n"
     ]
    }
   ],
   "source": [
    "categories = ['analyst', 'insiders', 'fundamental', 'macro', 'model', 'news', 'option', 'other', 'pv', 'risk', 'sentiment', 'socialmedia', 'earnings']\n",
    "output_dir = \"data\"\n",
    "output_file = os.path.join(output_dir, 'GLB/categories_delay1.csv')\n",
    "# 自定义参数，覆盖部分默认值\n",
    "\n",
    "default_params = {\n",
    "            'delay': 1,\n",
    "            'instrumentType': 'EQUITY',\n",
    "            'limit': 30,\n",
    "            'offset': 0,\n",
    "            'region': 'GLB',\n",
    "            'universe': 'TOP3000'\n",
    "        }\n",
    "for category in categories:\n",
    "        params = default_params.copy()\n",
    "        params['category'] = category\n",
    "        results_df = fetch_data(s, params)\n",
    "        if not results_df.empty:\n",
    "            write_to_csv(results_df, output_file)\n",
    "            print(f\"类别 '{category}' 的数据已追加到 {output_file}\")\n",
    "        else:\n",
    "            print(f\"类别 '{category}' 未返回数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869ac9c80bfd3253",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T06:39:00.330756Z",
     "start_time": "2025-04-02T06:38:55.541700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别 'fundamental28' 的数据已追加到 output/datafields5.csv\n",
      "类别 'fundamental6' 的数据已追加到 output/datafields5.csv\n",
      "类别 'analyst48' 未返回数据\n",
      "类别 'analyst14' 的数据已追加到 output/datafields5.csv\n",
      "类别 'news18' 的数据已追加到 output/datafields5.csv\n",
      "类别 'news87' 未返回数据\n",
      "类别 'model26' 的数据已追加到 output/datafields5.csv\n",
      "类别 'model29' 的数据已追加到 output/datafields5.csv\n",
      "类别 'model30' 的数据已追加到 output/datafields5.csv\n",
      "类别 'model51' 的数据已追加到 output/datafields5.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_ids = ['analyst14', 'fundamental6', 'analyst48', 'analyst14', 'news18', 'news87', 'model26', 'model29','model30', 'model51']\n",
    "output_dir = \"data\"\n",
    "output_data_fields = os.path.join(output_dir, 'datafields5.csv')\n",
    "for dataset_id in dataset_ids:\n",
    "    df = get_datafields(s, dataset_id = dataset_id, region='USA', universe='TOP3000', delay=1)\n",
    "    df = df[df['type'] == 'MATRIX']\n",
    "    if not df.empty:\n",
    "        write_to_csv(df, output_data_fields)\n",
    "        print(f\"类别 '{dataset_id}' 的数据已追加到 {output_data_fields}\")\n",
    "    else:\n",
    "        print(f\"类别 '{dataset_id}' 未返回数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0263b53a6f13453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取的 dataset_ids: ['analyst14', 'analyst15', 'analyst39', 'analyst4', 'analyst45', 'analyst46', 'analyst69', 'insiders1', 'insiders5', 'fundamental17', 'fundamental22', 'fundamental23', 'fundamental28', 'fundamental44', 'fundamental6', 'fundamental89', 'other395', 'fundamental65', 'model110', 'model139', 'model144', 'model16', 'model230', 'model25', 'model250', 'model26', 'model29', 'model30', 'model32', 'model33', 'model36', 'model38', 'model39', 'other176', 'news104', 'news17', 'news18', 'news20', 'news31', 'news37', 'news38', 'news46', 'news54', 'news7', 'other7', 'other455', 'pv1', 'pv13', 'pv29', 'pv3', 'pv37', 'pv70', 'pv96', 'univ1', 'univ2', 'risk60', 'risk70', 'risk72', 'sentiment27', 'other100', 'socialmedia15', 'socialmedia39']\n",
      "类别 'analyst14' 的数据已写入 data/ASI/analyst14_matrix.csv\n",
      "类别 'analyst15' 的数据已写入 data/ASI/analyst15_matrix.csv\n",
      "类别 'analyst39' 的数据已写入 data/ASI/analyst39_matrix.csv\n",
      "类别 'analyst4' 的数据已写入 data/ASI/analyst4_matrix.csv\n",
      "类别 'analyst45' 未返回数据\n",
      "类别 'analyst46' 的数据已写入 data/ASI/analyst46_matrix.csv\n",
      "类别 'analyst69' 的数据已写入 data/ASI/analyst69_matrix.csv\n",
      "类别 'insiders1' 未返回数据\n",
      "类别 'insiders5' 未返回数据\n",
      "类别 'fundamental17' 的数据已写入 data/ASI/fundamental17_matrix.csv\n",
      "类别 'fundamental22' 未返回数据\n",
      "类别 'fundamental23' 的数据已写入 data/ASI/fundamental23_matrix.csv\n",
      "类别 'fundamental28' 的数据已写入 data/ASI/fundamental28_matrix.csv\n",
      "类别 'fundamental44' 的数据已写入 data/ASI/fundamental44_matrix.csv\n",
      "类别 'fundamental6' 的数据已写入 data/ASI/fundamental6_matrix.csv\n",
      "类别 'fundamental89' 的数据已写入 data/ASI/fundamental89_matrix.csv\n",
      "类别 'other395' 的数据已写入 data/ASI/other395_matrix.csv\n",
      "类别 'fundamental65' 的数据已写入 data/ASI/fundamental65_matrix.csv\n",
      "类别 'model110' 的数据已写入 data/ASI/model110_matrix.csv\n",
      "类别 'model139' 未返回数据\n",
      "类别 'model144' 的数据已写入 data/ASI/model144_matrix.csv\n",
      "类别 'model16' 的数据已写入 data/ASI/model16_matrix.csv\n",
      "类别 'model230' 的数据已写入 data/ASI/model230_matrix.csv\n",
      "类别 'model25' 的数据已写入 data/ASI/model25_matrix.csv\n",
      "类别 'model250' 的数据已写入 data/ASI/model250_matrix.csv\n",
      "类别 'model26' 的数据已写入 data/ASI/model26_matrix.csv\n",
      "类别 'model29' 的数据已写入 data/ASI/model29_matrix.csv\n",
      "类别 'model30' 的数据已写入 data/ASI/model30_matrix.csv\n",
      "类别 'model32' 的数据已写入 data/ASI/model32_matrix.csv\n",
      "类别 'model33' 的数据已写入 data/ASI/model33_matrix.csv\n",
      "类别 'model36' 的数据已写入 data/ASI/model36_matrix.csv\n",
      "类别 'model38' 的数据已写入 data/ASI/model38_matrix.csv\n",
      "类别 'model39' 的数据已写入 data/ASI/model39_matrix.csv\n",
      "类别 'other176' 的数据已写入 data/ASI/other176_matrix.csv\n",
      "类别 'news104' 未返回数据\n",
      "类别 'news17' 未返回数据\n",
      "类别 'news18' 的数据已写入 data/ASI/news18_matrix.csv\n",
      "类别 'news20' 未返回数据\n",
      "类别 'news31' 未返回数据\n",
      "类别 'news37' 未返回数据\n",
      "类别 'news38' 未返回数据\n",
      "类别 'news46' 的数据已写入 data/ASI/news46_matrix.csv\n",
      "类别 'news54' 未返回数据\n",
      "类别 'news7' 的数据已写入 data/ASI/news7_matrix.csv\n",
      "类别 'other7' 未返回数据\n",
      "类别 'other455' 的数据已写入 data/ASI/other455_matrix.csv\n",
      "类别 'pv1' 的数据已写入 data/ASI/pv1_matrix.csv\n",
      "类别 'pv13' 的数据已写入 data/ASI/pv13_matrix.csv\n",
      "类别 'pv29' 未返回数据\n",
      "类别 'pv3' 的数据已写入 data/ASI/pv3_matrix.csv\n",
      "类别 'pv37' 的数据已写入 data/ASI/pv37_matrix.csv\n",
      "类别 'pv70' 未返回数据\n",
      "类别 'pv96' 的数据已写入 data/ASI/pv96_matrix.csv\n",
      "类别 'univ1' 未返回数据\n",
      "类别 'univ2' 未返回数据\n",
      "类别 'risk60' 未返回数据\n",
      "类别 'risk70' 的数据已写入 data/ASI/risk70_matrix.csv\n",
      "类别 'risk72' 的数据已写入 data/ASI/risk72_matrix.csv\n",
      "类别 'sentiment27' 未返回数据\n",
      "类别 'other100' 未返回数据\n",
      "类别 'socialmedia15' 未返回数据\n",
      "类别 'socialmedia39' 未返回数据\n"
     ]
    }
   ],
   "source": [
    "# 数据集 ID 列表\n",
    "\"\"\"\n",
    "dataset_ids = ['analyst14', 'analyst15', 'analyst39', 'analyst4', \n",
    "               'analyst40', 'analyst69', 'analyst7', 'analyst81', \n",
    "               'analyst9', 'model52', 'model26', 'model30', 'fundamental17',\n",
    "               'fundamental28', 'fundamental6', 'news18', 'pv1']\n",
    "\"\"\"\n",
    "output_dir = \"data/ASI\"\n",
    "\n",
    "# 确保输出目录存在\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"创建输出目录: {output_dir}\")\n",
    "    \n",
    "csv_file_path = os.path.join(output_dir, \"categories_delay1.csv\")  # 替换为你的 CSV 文件路径\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# 提取 id 列，生成 dataset_ids 列表\n",
    "dataset_ids = df['id'].tolist()\n",
    "\n",
    "# 打印 dataset_ids，确认结果\n",
    "print(\"提取的 dataset_ids:\", dataset_ids)\n",
    "\n",
    "# 假设 s 是一个已定义的会话对象（例如 requests.Session）\n",
    "# s = requests.Session()\n",
    "\n",
    "# 遍历 dataset_ids，为每个 dataset_id 生成一个单独的 CSV 文件\n",
    "for dataset_id in dataset_ids:\n",
    "    # 构造输出文件路径，例如 data/analyst14.csv\n",
    "    output_file = os.path.join(output_dir, f\"{dataset_id}_matrix.csv\")\n",
    "    \n",
    "    # 获取数据\n",
    "    df = get_datafields(s, dataset_id=dataset_id, region='ASI', universe='MINVOL1M', delay=1)\n",
    "    \n",
    "    # 过滤 type 为 'MATRIX' 的数据\n",
    "    df = df[df['type'] == 'MATRIX']\n",
    "    \n",
    "    # 检查 DataFrame 是否为空\n",
    "    if not df.empty:\n",
    "        # 写入 CSV 文件\n",
    "        write_to_csv(df, output_file)\n",
    "        print(f\"类别 '{dataset_id}' 的数据已写入 {output_file}\")\n",
    "    else:\n",
    "        print(f\"类别 '{dataset_id}' 未返回数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cdd01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已读取文件: data/USA/fundamental6.csv\n",
      "已读取文件: data/USA/fundamental17.csv\n",
      "已读取文件: data/USA/fundamental28.csv\n",
      "已读取文件: data/USA/fundamental23.csv\n",
      "已将 4 个文件合并到 output/merged_fnd_data.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 输入参数\n",
    "dataset_ids = ['fundamental6']  # 需要合并的 dataset_ids\n",
    "input_dir = \"data/USA\"  # CSV 文件所在的目录\n",
    "output_dir = \"output\"\n",
    "output_file = os.path.join(output_dir, \"fundamental6.txt\")  # 合并后的 TXT 文件路径\n",
    "\n",
    "# 存储所有数据的 DataFrame 列表\n",
    "dfs = []\n",
    "\n",
    "# 遍历 dataset_ids，读取对应的 CSV 文件\n",
    "for dataset_id in dataset_ids:\n",
    "    csv_file = os.path.join(input_dir, f\"{dataset_id}.csv\")\n",
    "    \n",
    "    # 检查文件是否存在\n",
    "    if not os.path.exists(csv_file):\n",
    "        print(f\"文件 {csv_file} 不存在，跳过\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 读取 CSV 文件\n",
    "        df = pd.read_csv(csv_file)\n",
    "        dfs.append(df)\n",
    "        print(f\"已读取文件: {csv_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"读取文件 {csv_file} 时发生错误: {e}\")\n",
    "        continue\n",
    "\n",
    "# 检查是否有文件被成功读取\n",
    "if not dfs:\n",
    "    print(\"没有成功读取任何文件，无法合并\")\n",
    "else:\n",
    "    # 合并所有 DataFrame\n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # 将合并后的数据写入 TXT 文件（以 CSV 格式写入）\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"已将 {len(dfs)} 个文件合并到 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2783ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
